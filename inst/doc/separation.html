<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Ioannis Kosmidis" />

<meta name="date" content="2017-05-16" />

<title>Detecting separation and infinite estimates in binomial response GLMs</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Detecting separation and infinite estimates in binomial response GLMs</h1>
<h4 class="author"><a href="http://www.ikosmidis.com">Ioannis Kosmidis</a></h4>
<h4 class="date">16 May 2017</h4>



<div id="the-brglm2-package" class="section level1">
<h1>The <strong>brglm2</strong> package</h1>
<p>Along with methods for improving the estimation of generalized linear models (see <a href="https://cran.r-project.org/package=brglm2/brglm2.pdf"><code>iteration</code></a> vignette), <a href="https://github.com/ikosmidis/brglm2"><strong>brglm2</strong></a> provides <em>pre-fit</em> and <em>post-fit</em> methods for the detection of separation and of infinite maximum likelihood estimates in binomial response generalized linear models.</p>
<p>The key methods are <code>detect_separation</code> and <code>check_infinite_estimates</code> and this vignettes describes their use.</p>
<p><strong>Note:</strong></p>
<p>‘detect_separation’ and <code>check_infinite_estimates</code> will be removed from ‘brglm2’ at version 0.8. New versions are now maintained in the ‘detectseparation’ R package at &lt;URL: <a href="https://cran.r-project.org/package=detectseparation" class="uri">https://cran.r-project.org/package=detectseparation</a>&gt;. In order to use the version in ‘detect_separation’ load first ‘brglm2’ and then ‘detectseparation’, i.e. ‘library(brglm2); library(detectseparation)’.</p>
</div>
<div id="checking-for-infinite-estimates" class="section level1">
<h1>Checking for infinite estimates</h1>
<p><span class="citation">Heinze and Schemper (2002)</span> used a logistic regression model to analyze data from a study on endometrial cancer. <span class="citation">Agresti (2015, Section 5.7)</span> provide details on the data set. Below, we fit a probit regression model with the same linear predictor as the logistic regression model in <span class="citation">Heinze and Schemper (2002)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(<span class="st">&quot;brglm2&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">data</span>(<span class="st">&quot;endometrial&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;brglm2&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a>modML &lt;-<span class="st"> </span><span class="kw">glm</span>(HG <span class="op">~</span><span class="st"> </span>NV <span class="op">+</span><span class="st"> </span>PI <span class="op">+</span><span class="st"> </span>EH, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;probit&quot;</span>), <span class="dt">data =</span> endometrial)</span>
<span id="cb1-4"><a href="#cb1-4"></a>theta_mle &lt;-<span class="st"> </span><span class="kw">coef</span>(modML)</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="kw">summary</span>(modML)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">#&gt; </span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">#&gt; Call:</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">#&gt; glm(formula = HG ~ NV + PI + EH, family = binomial(&quot;probit&quot;), </span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co">#&gt;     data = endometrial)</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co">#&gt; </span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co">#&gt; Deviance Residuals: </span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co">#&gt;      Min        1Q    Median        3Q       Max  </span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="co">#&gt; -1.47007  -0.67917  -0.32978   0.00008   2.74898  </span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="co">#&gt; </span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="co">#&gt; (Intercept)   2.18093    0.85732   2.544 0.010963 *  </span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co">#&gt; NV            5.80468  402.23641   0.014 0.988486    </span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co">#&gt; PI           -0.01886    0.02360  -0.799 0.424066    </span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="co">#&gt; EH           -1.52576    0.43308  -3.523 0.000427 ***</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="co">#&gt; ---</span></span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="co">#&gt; </span></span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="co">#&gt; </span></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="co">#&gt;     Null deviance: 104.90  on 78  degrees of freedom</span></span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="co">#&gt; Residual deviance:  56.47  on 75  degrees of freedom</span></span>
<span id="cb1-28"><a href="#cb1-28"></a><span class="co">#&gt; AIC: 64.47</span></span>
<span id="cb1-29"><a href="#cb1-29"></a><span class="co">#&gt; </span></span>
<span id="cb1-30"><a href="#cb1-30"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 17</span></span></code></pre></div>
<p>As is the case for the logistic regression in <span class="citation">Heinze and Schemper (2002)</span>, the maximum likelihood (ML) estimate of the parameter for <code>NV</code> is actually infinite. The reported, apparently finite value is merely due to false convergence of the iterative estimation procedure. The same is true for the estimated standard error, and, hence the value <code>r round(coef(summary(modML))[&quot;NV&quot;, &quot;z value&quot;], 3)</code> for the <span class="math inline">\(z\)</span>-statistic cannot be trusted for inference on the size of the effect for <code>NV</code>.</p>
<p>‘<span class="citation">Lesaffre and Albert (1989, Section 4)</span> describe a procedure that can hint on the occurrence of infinite estimates. In particular, the model is successively refitted, by increasing the maximum number of allowed IWLS iterations at east step. At east step the estimated asymptotic standard errors are divided to the corresponding ones from the first fit. If the sequence of ratios diverges, then the maximum likelihood estimate of the corresponding parameter is minus or plus infinity. The following code chunk applies this process to <code>modML</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">check_infinite_estimates</span>(modML)</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="co">#&gt; Warning: &#39;check_infinite_estimates&#39; will be removed from &#39;brglm2&#39; at version</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co">#&gt; 0.8. A new version of &#39;check_infinite_estimates&#39; is now maintained in the</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co">#&gt; &#39;detectseparation&#39; package.</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co">#&gt;       (Intercept)           NV       PI       EH</span></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co">#&gt;  [1,]    1.000000 1.000000e+00 1.000000 1.000000</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">#&gt;  [2,]    1.320822 1.710954e+00 1.352585 1.523591</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co">#&gt;  [3,]    1.410578 5.468665e+00 1.483265 1.617198</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="co">#&gt;  [4,]    1.413505 3.225927e+01 1.490753 1.618462</span></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="co">#&gt;  [5,]    1.413559 3.311464e+02 1.490923 1.618484</span></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="co">#&gt;  [6,]    1.413560 5.786011e+03 1.490924 1.618484</span></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co">#&gt;  [7,]    1.413560 1.704229e+05 1.490924 1.618484</span></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="co">#&gt;  [8,]    1.413560 3.232598e+06 1.490924 1.618484</span></span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="co">#&gt;  [9,]    1.413560 5.402789e+06 1.490924 1.618484</span></span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co">#&gt; [10,]    1.413560 9.295902e+06 1.490924 1.618484</span></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="co">#&gt; [11,]    1.413560 2.290248e+07 1.490924 1.618484</span></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co">#&gt; [12,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="co">#&gt; [13,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="co">#&gt; [14,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="co">#&gt; [15,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="co">#&gt; [16,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-22"><a href="#cb2-22"></a><span class="co">#&gt; [17,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="co">#&gt; [18,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-24"><a href="#cb2-24"></a><span class="co">#&gt; [19,]    1.413560 3.953686e+07 1.490924 1.618484</span></span>
<span id="cb2-25"><a href="#cb2-25"></a><span class="co">#&gt; [20,]    1.413560 3.953686e+07 1.490924 1.618484</span></span></code></pre></div>
<p>Clearly, the ratios of estimated standard errors diverge for <code>NV</code>.</p>
</div>
<div id="detecting-separation" class="section level1">
<h1>Detecting separation</h1>
<p><code>detect_separation</code> tests for the occurrence of complete or quasi-complete separation in datasets for binomial response generalized linear models, and finds which of the parameters will have infinite maximum likelihood estimates. <code>detect_separation</code> relies on the linear programming methods developed in <span class="citation">Konis (2007)</span>.</p>
<p><code>detect_separation</code> is <em>pre-fit</em> method, in the sense that it does not need to estimate the model to detect separation and/or identify infinite estimates. For example</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>endometrial_sep &lt;-<span class="st"> </span><span class="kw">glm</span>(HG <span class="op">~</span><span class="st"> </span>NV <span class="op">+</span><span class="st"> </span>PI <span class="op">+</span><span class="st"> </span>EH, <span class="dt">data =</span> endometrial,</span>
<span id="cb3-2"><a href="#cb3-2"></a>                       <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>),</span>
<span id="cb3-3"><a href="#cb3-3"></a>                       <span class="dt">method =</span> <span class="st">&quot;detect_separation&quot;</span>)</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co">#&gt; Warning: &#39;detect_separation&#39; will be removed from &#39;brglm2&#39; at version 0.8. A</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co">#&gt; new version of &#39;detect_separation&#39; is now maintained in the &#39;detectseparation&#39;</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co">#&gt; package.</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>endometrial_sep</span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co">#&gt; Separation: TRUE </span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">#&gt; Existence of maximum likelihood estimates</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co">#&gt; (Intercept)          NV          PI          EH </span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="co">#&gt;           0         Inf           0           0 </span></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co">#&gt; 0: finite value, Inf: infinity, -Inf: -infinity</span></span></code></pre></div>
<p>The <code>detect_separation</code> method reports that there is separation in the data, that the estimates for <code>(Intercept)</code>, <code>PI</code> and <code>EH</code> are finite (coded 0), and that the estimate for <code>NV</code> is plus infinity. So, the actual maximum likelihood estimates are</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">coef</span>(modML) <span class="op">+</span><span class="st"> </span>endometrial_sep<span class="op">$</span>betas</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="co">#&gt; (Intercept)          NV          PI          EH </span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co">#&gt;  2.18092821         Inf -0.01886444 -1.52576146</span></span></code></pre></div>
<p>and the estimated standard errors are</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">coef</span>(<span class="kw">summary</span>(modML))[, <span class="st">&quot;Std. Error&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="kw">abs</span>(endometrial_sep<span class="op">$</span>betas)</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co">#&gt; (Intercept)          NV          PI          EH </span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co">#&gt;  0.85732428         Inf  0.02359861  0.43307925</span></span></code></pre></div>
</div>
<div id="citation" class="section level1">
<h1>Citation</h1>
<p>If you found this vignette or <strong>brglm2</strong>, in general, useful, please consider citing <strong>brglm2</strong> and the associated paper. You can find information on how to do this by typing <code>citation(&quot;brglm2&quot;)</code>.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-agresti:15">
<p>Agresti, A. 2015. <em>Foundations of Linear and Generalized Linear Models</em>. Wiley Series in Probability and Statistics. Wiley.</p>
</div>
<div id="ref-heinze:02">
<p>Heinze, G., and M. Schemper. 2002. “A Solution to the Problem of Separation in Logistic Regression.” <em>Statistics in Medicine</em> 21: 2409–19.</p>
</div>
<div id="ref-konis:07">
<p>Konis, Kjell. 2007. “Linear Programming Algorithms for Detecting Separated Data in Binary Logistic Regression Models.” DPhil, University of Oxford. <a href="https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a">https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a</a>.</p>
</div>
<div id="ref-lesaffre:89">
<p>Lesaffre, E., and A. Albert. 1989. “Partial Separation in Logistic Discrimination.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 51 (1): 109–16. <a href="https://www.jstor.org/stable/2345845">https://www.jstor.org/stable/2345845</a>.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
